{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y = tf.Variable(1)\n",
    "b = tf.identity(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(b,feed_dict={y:3})) #使用3 替换掉\n",
    "    #tf.Variable(1)的输出结果，所以打印出来3 \n",
    "    #feed_dict{y.name:3} 和上面写法等价\n",
    "\n",
    "    print(sess.run(b))  #由于feed只在调用他的方法范围内有效，所以这个打印的结果是 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xibo\\Anaconda2\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "10000.0\n",
      "10000.0\n",
      "10000.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "state = tf.Variable(0.0,dtype=tf.float32)\n",
    "one = tf.constant(1.0,dtype=tf.float32)\n",
    "new_val = tf.add(state, one)\n",
    "update = tf.assign(state, new_val) #返回tensor， 值为new_val\n",
    "update2 = tf.assign(state, 10000)  #没有fetch，便没有执行\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        #print(sess.run(update))\n",
    "        print(sess.run(update2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations = tf.placeholder(tf.float32, None, name=\"input_x\")\n",
    "x = 1\n",
    "state = tf.Variable(0.0,dtype=tf.float32)\n",
    "test = tf.add(state, observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.zeros(shape=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros(shape=[10,3]))\n",
    "x = tf.Variable(tf.zeros(shape=[3,9]))\n",
    "#Variable必须初始化以后才有具体的值。\n",
    "\n",
    "W = tf.Variable([[ 1 , 2 , 3],[ 2 , 3 ,4]])\n",
    "x = tf.Variable([[1],[2],[3]])\n",
    "y = tf.placeholder(tf.int32 , [None, None])  # 输出占位符（预期输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.matmul(W,x )\n",
    "init=tf.global_variables_initializer()\n",
    "b = tf.matmul(W,y )\n",
    "input = [ [ 1, 2, 3, 4, 5, 6],[ 1, 2, 3, 4, 5, 6],[ 1, 2, 3, 4, 5, 6] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14]\n",
      " [20]]\n",
      "[[ 6 12 18 24 30 36]\n",
      " [ 9 18 27 36 45 54]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:#创建sess\n",
    "    sess.run(init)\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(b,feed_dict={y:input}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 4  # 环境信息observation的维度D为4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#策略网络的具体结构。\n",
    "#该网络将接受observation作为信息输入，最后输出一个概率值用以选择Action\n",
    "#这里只有两个Action，向左施加力或者向右施加力，因此可以通过一个概率值决定\n",
    "\n",
    "observations = tf.placeholder(tf.float32, [None, D], name=\"input_x\")\n",
    "#创建输入信息observations的placeholder其维度为D\n",
    "\n",
    "#使用tf.contrib.layers.xavier_initializer方法初始化隐含层的权重W1，其维度为[D,H]\n",
    "W1 = tf.get_variable(\"W1\", shape=[D, H],initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer1 = tf.nn.relu(tf.matmul(observations, W1))\n",
    "#接着使用tf.matmul将环境信息observations乘上W1再使用relu激活函数处理得到隐含层的输出layer1\n",
    "\n",
    "#使用tf.contrib.layers.xavier_initializer方法初始化隐含层的权重W2，其维度为[H,1]\n",
    "W2 = tf.get_variable(\"W2\", shape=[H, 1],initializer=tf.contrib.layers.xavier_initializer())\n",
    "score = tf.matmul(layer1, W2)\n",
    "probability = tf.nn.sigmoid(score)\n",
    "#将隐含层输出layer1乘以W2后，使用Sigmoid激活函数处理得到最后的输出概率\n",
    "\n",
    "\n",
    "# From here we define the parts of the network needed for learning a good policy.\n",
    "tvars = tf.trainable_variables()#获取策略网络中全部可训练的参数tvars\n",
    "input_y = tf.placeholder(tf.float32, [None, 1], name=\"input_y\")\n",
    "advantages = tf.placeholder(tf.float32, name=\"reward_signal\")\n",
    "#定义人工设置的虚拟label的占位符input_y\n",
    "#以及每个Action的潜在价值的占位符\n",
    "\n",
    "#当Action取值为1的概率为probability(即策略网络输出的概率)\n",
    "#当Action取值为0的概率为1-probability\n",
    "#label取值与Action相反，即label=1-Action。\n",
    "#当Action为1时，label为0，此时loglik=tf.log(probability),Action取值为1的概率的对数\n",
    "#当Action为0时，label为1，此时loglik=tf.log(1-probability),Action取值为0的概率的对数\n",
    "#所以，loglik其实就是当前Action对应的概率的对数\n",
    "loglik = tf.log(input_y * (input_y - probability) + (1 - input_y) * (input_y + probability))\n",
    "\n",
    "loss = -tf.reduce_mean(loglik * advantages)\n",
    "#将loglik与潜在价值advanages相乘，并取负数作为损失，即优化目标\n",
    "newGrads = tf.gradients(loss, tvars)\n",
    "#使用tf.gradients求解模型参数关于loss的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Log:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(loglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Neg:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
